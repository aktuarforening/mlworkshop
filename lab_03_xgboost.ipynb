{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Trees-model: XGBoost\n",
    "\n",
    "I denne notebook vil vi afprøve en model med en [*XGBoost*](https://xgboost.readthedocs.io/en/stable/)-predictor, der tilhører familien af &#128073; [*Gradient Boosting Trees*-predictors](slides/08_xgboost.ipynb).\n",
    "\n",
    "## Import af python-afhængigheder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from feature_engine.selection import (\n",
    "    DropConstantFeatures,\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from workshop.utils import DropFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indlæs \"rådata\" for 2015-18\n",
    "df = pd.read_parquet(\"data/train.parquet\")\n",
    "\n",
    "# dan binomial \"target\"-variabel, der angiver, om der har været skade(r) eller ej\n",
    "y = df[\"skadesantal\"].values > 0\n",
    "\n",
    "# instantiér generator til split af data, random state sættes for at kunne reproducere split\n",
    "split_generator = ShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "\n",
    "# generér indices for de to splits\n",
    "train_index, val_index = next(split_generator.split(df))\n",
    "\n",
    "# opdel data i trænings- og valideringssæt\n",
    "X_train, y_train = df.iloc[train_index], y[train_index]\n",
    "X_val, y_val = df.iloc[val_index], y[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-transformationer\n",
    "\n",
    "*XGBoost*-predictoren kan håndtere de fleste inputs. Den kan håndtere kategoriske variable og missing-værdier *under the hood*.\n",
    "\n",
    "Derfor bliver vores data-transformations-pipeline minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    \"aar\",\n",
    "    \"idnummer\",\n",
    "    \"skadesudgift\",\n",
    "    \"skadesantal\",\n",
    "]\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"drop_features_blacklist\", DropFeatures(blacklist)),\n",
    "        (\"drop_constant_features\", DropConstantFeatures(missing_values=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# vis pipeline\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-træning\n",
    "Vi anvender konkret predictoren [`XGBClassifier`](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier) fra `xgboost`. Vi instantierer predictoren med dens default-parameter-værdier. \n",
    "\n",
    "Vi udvider vores data-transformations-pipeline med predictoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiér predictor\n",
    "predictor = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    enable_categorical=True,\n",
    ")\n",
    "\n",
    "# udvid pipeline med vores predictor\n",
    "pipe.steps.append([\"predictor\", predictor])\n",
    "\n",
    "# visualize pipeline\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline inkl. predictor fittes under ét på vores træningsdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-evaluering\n",
    "\n",
    "Vi plotter ROC-kurverne for modellen på trænings- og valideringssættet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beregn true positive rate og false positive rate for trænings- og valideringssæt\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_train, [0 for _ in range(len(y_train))])\n",
    "train_fpr, train_tpr, _ = roc_curve(y_train, pipe.predict_proba(X_train)[:, 1])\n",
    "test_fpr, test_tpr, _ = roc_curve(y_val, pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "# plot ROC-kurver\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle=\"--\", label=\"Naïve\")\n",
    "plt.plot(train_fpr, train_tpr, label=\"Train\")\n",
    "plt.plot(test_fpr, test_tpr, label=\"Validation\")\n",
    "\n",
    "# formatér og display plot\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bemærker, at ROC-kurven for træningssættet ser markant bedre ud end den for valideringssættet.\n",
    "\n",
    "Vi beregner for begge sæt [*ROC AUC*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beregn ROC AUC på både trænings- og valideringssæt\n",
    "auc_train = roc_auc_score(y_train, pipe.predict_proba(X_train)[:, 1])\n",
    "auc_val = roc_auc_score(y_val, pipe.predict_proba(X_val)[:, 1])\n",
    "print(\"ROC AUC train: \", auc_train, \"\\nROC AUC val: \", auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det bemærkes, at :\n",
    "\n",
    "1. Modellen performer signifikant bedre end en naiv model på både trænings- og valideringssæt\n",
    "2. Modellen performer voldsomt meget bedre på træningssættet end på valideringssættet. Det er et klart tegn på *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-diagnostik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBoost` har nyttige indbyggede værktøjer til at beregne og plotte feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(pipe.named_steps[\"predictor\"], max_num_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bemærk**, hvor parametrene i en `LogisticRegression` har en pæn fortolkning, går forklarligheden fløjten i en black-box-model som `xgboost`.\n",
    "\n",
    "Vi inspicerer fordelingen af de prædikterede sandsynligheder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pipe.predict_proba(X_train)[:, 1])\n",
    "plt.xlim(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser igen en \"pæn\" fordeling af prædiktionerne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "Som I kan se af dokumentationen for [`XGBClassifier`](https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster), er der voldsomt mange håndtag, man kan skrue på i bestræbelserne på at optimere modellens prædiktive performance.\n",
    "\n",
    "Vi vælger at tune parametrene *learning_rate*, *max_depth* og *n_estimators* simultant.\n",
    "\n",
    "Vi anvender et simpelt `GridSearch` til formålet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definér parameter-grid, der skal gennemsøges\n",
    "param_grid = {\n",
    "    \"predictor__learning_rate\": [0.1, 0.3],\n",
    "    \"predictor__max_depth\": [3, 6],\n",
    "    \"predictor__n_estimators\": [100, 250],\n",
    "}\n",
    "\n",
    "# Forbered GridSearch\n",
    "# Bemærk, at vi her bruger vores split_generator til at generere trænings- og valideringssæt\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=split_generator,\n",
    "    scoring=\"roc_auc\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "# Udfør grid search - bemærk, vi giver hele datasættet (2015-18) som input og overlader det til split-generatoren at splitte det i trænings- og valideringssæt\n",
    "grid.fit(df, y)\n",
    "\n",
    "print(\"Disse parametre giver den bedste performance: \", grid.best_params_)\n",
    "print(\"Med en ROC AUC på: \", grid.best_score_)\n",
    "\n",
    "# Udskriv resultater\n",
    "results = pd.DataFrame.from_records(grid.cv_results_[\"params\"])\n",
    "results[\"mean_valid_score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "results[\"mean_train_score\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "print(\"Resultater for grid search:\")\n",
    "results.sort_values(\"mean_valid_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "På nettet kan man finde mange bud på, hvordan `xgboost` skal tunes, f.eks. [dette](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kan I gøre det bedre?\n",
    "\n",
    "&#128073; [Model Lab](slides/09_kaggle.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
