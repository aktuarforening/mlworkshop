{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model: Logistisk Regression\n",
    "\n",
    "Udviklingen af en ML-model består typisk i at prøve en masse forskellige eksperimenter, predictors og model tuning af for at finde frem til den løsning, der performer bedst på ens data.\n",
    "\n",
    "Det er *god praksis* i første iteration at udvikle en simpel *baseline*-model, der kan fungere som benchmark for - mere avancerede - model-arkitekturer i senere iterationer.\n",
    "\n",
    "I denne notebook udvikler vi en *baseline*-model, der anvender velkendt *logistisk regression* som predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import af python-afhængigheder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from feature_engine.selection import (\n",
    "    DropConstantFeatures,\n",
    "    DropCorrelatedFeatures,\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from workshop.utils import DropFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som det ses, kommer vi til at anvende mange værktøjer fra pakken [scikit-learn](https://scikit-learn.org/stable/index.html) (=`sklearn`), der (fortsat) er det førende framework til generel Machine Learning i Python.\n",
    "\n",
    "Specielt kommer vi til at bruge [`sklearn.pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), der giver en stringent programmatisk struktur til at definere den samlede \"opskrift\" på vores ML-model.\n",
    "\n",
    "Til sidst anvender vi \"opskriften\" til at træne vores samlede model.\n",
    "\n",
    "**ADVARSEL**: at udvikle en model med `sklearn.pipeline` kan umiddelbart virke ret tungt og besværligt, og det kan måske være svært at se, hvad man får ud af det. Vi vender tilbage til, hvorfor det er attraktivt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indlæs \"rådata\" for 2015-18\n",
    "df = pd.read_parquet(\"data/train.parquet\")\n",
    "\n",
    "# beregn binomialt target, der angiver, om der har været skade(r) eller ej\n",
    "y = df[\"skadesantal\"].values > 0\n",
    "\n",
    "# instantiér generator til split af data, 'random_state' sættes for at kunne reproducere split\n",
    "split_generator = ShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "\n",
    "# generér indices for de to datasæt\n",
    "train_index, val_index = next(split_generator.split(df))\n",
    "\n",
    "# opdel data i trænings- og valideringssæt\n",
    "X_train, y_train = df.iloc[train_index], y[train_index]\n",
    "X_val, y_val = df.iloc[val_index], y[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-transformationer\n",
    "\n",
    "En (meget) stor del af arbejdet med at udvikle en ML-model består typisk i at definere de transformationer, som data skal gennemgå, førend de fødes ind i selve predictoren. Denne proces kaldes i flæng også for \"data preprocessing\" og \"feature engineering\".\n",
    "\n",
    "Vi anvender til dette formål en række [`transformers`](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin), der hver især transformerer data - typisk på baggrund af automatiseret \"læring\" fra træningssættet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop variable\n",
    "Først skridt i vores data-transformations-pipeline er at fjerne uønskede features.\n",
    "\n",
    "For eksempel bør vi indlysende fjerne features, der indeholder direkte information om vores target, da der ellers ville være tale om snyd, og vi ville ende ud med en ubrugelig model.\n",
    "\n",
    "Vi instantierer til det formål en simpel `DropFeatures`-transformer, der blot fjerner features fra en liste med brugerdefinerede, hardcodede navne på features: `blacklist` gennem sin `transform()`-metode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    # 'skadesudgift' og 'skadesantal' er direkte afledt af target-variablen, og kan derfor ikke bruges til at prædiktere den\n",
    "    \"skadesudgift\",\n",
    "    \"skadesantal\",\n",
    "    # vi fjerner 'aar', da vi indtil videre bortser fra eventuelle tidslige mønstre i data\n",
    "    \"aar\",\n",
    "    # 'idnummer' er en unik identifikator for hver kunde, der ikke - i sig selv - indeholder signal\n",
    "    \"idnummer\",\n",
    "]\n",
    "drop_features = DropFeatures(blacklist)\n",
    "\n",
    "# demonstrér transformer\n",
    "print(\n",
    "    \"Tilbageværende features efter transformation:\",\n",
    "    drop_features.transform(X_train).columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "God ML-skik tilsiger, at omfanget af \"hard-coded\" variabel-fravalg - som ovenstående - skal holdes på et minimum. En tommelfingerregel er, at jo færre \"hardcodede\"-variabelnavne der er i koden, desto bedre.\n",
    "\n",
    "I stedet ønsker man, at en eventuel deselektions-proces for variable i videst muligt omfang skal *læres* fra (/fittes på) vores *træningssæt*, og at den skal kunne generalisere til eventuelle nye variable.\n",
    "\n",
    "Et af de mest simple eksempler på en *tillært* variabel-deselektion, er at fjerne de variable, der er konstante i *træningssæt*, og derfor ikke vil bidrage med noget godt til vores predictor.\n",
    "\n",
    "Vi bruger en [`DropConstantFeatures`](https://feature-engine.trainindata.com/en/latest/api_doc/selection/DropConstantFeatures.html)-transformer, der gennem sin `fit()`-metode \"lærer\"/identificerer disse variable på træningssættet. Herefter kan transformeren - med `transform()` - transformerer nye datasæt og observationer herunder vores *validerings-* og *testsæt*.\n",
    "\n",
    "Nedenfor ses et eksempel på virkemåden for `DropConstantFeatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiér transformer\n",
    "drop_constant_features = DropConstantFeatures(missing_values=\"ignore\")\n",
    "\n",
    "# afprøv transformer på træningsdata\n",
    "# lær/identificér først features, der er konstante i træningsdata\n",
    "drop_constant_features.fit(X_train)\n",
    "\n",
    "# transformeren identificerer følgende variable som konstante\n",
    "removed_vars = list(\n",
    "    set(drop_constant_features.feature_names_in_)\n",
    "    - set(drop_constant_features.get_feature_names_out())\n",
    ")\n",
    "print(\n",
    "    \"Transformeren identificerer følgende features til at være konstante i træningsdata:\",\n",
    "    removed_vars,\n",
    ")\n",
    "\n",
    "# Herefter kan transformeren anvendes på et vilkårligt datasæt, hvorfra den fjerner ovenstående variable\n",
    "drop_constant_features.set_output(transform=\"pandas\")\n",
    "print(\n",
    "    \"Tilbageværende features efter transformation:\",\n",
    "    drop_constant_features.transform(X_train).columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herudover kan det give problemer for vores logistiske regression, hvis nogle af vores features er meget højt indbyrdes korrelerede. \n",
    "\n",
    "Derfor vil vi i vores pipeline også anvende en [`DropCorrelatedFeatures`](https://feature-engine.trainindata.com/en/latest/api_doc/selection/DropCorrelatedFeatures.html)-transformer, der identificerer og fjerner variable, der er meget højt indbyrdes korrelerede.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-transformationer\n",
    "\n",
    "Valget af predictor kan også have betydning for, om/hvordan de enkelte features i datasættet skal transformeres. Nogle predictors kan håndtere stort set alt, mens andre predictors - såsom logistisk regression - ikke accepterer missing-værdier. Det sidste gælder også for vores logistiske regression. \n",
    "\n",
    "Missing-værdier kan håndteres ved imputation, hvilket vi vil gøre i vores pipeline.\n",
    "\n",
    "Nedenfor definerer vi, hvordan hhv. numeriske og kategoriske features skal transformeres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeriske features\n",
    "\n",
    "Vi ønsker at imputere *missing*-værdier for numeriske features til variablernes respektive median-værdier.\n",
    "\n",
    "Derudover kan det erfaringsmæssigt for en logistisk regression være [nyttigt at standardisere/skalere de numeriske features]((https://forecastegy.com/posts/does-logistic-regression-require-feature-scaling/)), så de har middelværdi $\\mu=0$ og standardafvigelse $\\sigma=1$:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Vi sætter de to operationer sammen til en pipeline, som vi ønsker at anvende på *alle numeriske features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_num = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# afprøv pipeline på et udsnit af numeriske features i datasættet\n",
    "print(\n",
    "    \"Træningsdata før transformation:\\n\",\n",
    "    X_train.select_dtypes(include=\"number\").describe(),\n",
    ")\n",
    "\n",
    "# fit transformer på træningsdata\n",
    "transformer_num.set_output(transform=\"pandas\")\n",
    "transformer_num.fit(X_train.select_dtypes(include=\"number\"))\n",
    "\n",
    "# transformér træningsdata\n",
    "print(\n",
    "    \"Træningsdata efter transformation:\\n\",\n",
    "    transformer_num.transform(X_train.select_dtypes(include=\"number\")).describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kategoriske features\n",
    "\n",
    "Missing-værdier for kategoriske features ønsker vi at imputere til de respektive variablers hyppigst forekommende værdi i træningssættet.\n",
    "\n",
    "Da logistisk regression kun accepterer numeriske variable, specificerer vi desuden, at de kategoriske variable skal [\"one-hot\"-encodes](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_cat = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# afprøv pipeline på en enkelt variabel, \"geo\"\n",
    "geo = X_train[[\"geo\"]]\n",
    "print(\n",
    "    \"variablen 'geo' før transformation:\\n\",\n",
    "    geo,\n",
    "    \"\\n#missings:\",\n",
    "    geo.isna().sum().sum(),\n",
    ")\n",
    "\n",
    "transformer_cat.set_output(transform=\"pandas\")\n",
    "geo_transformed = transformer_cat.fit_transform(X_train[[\"geo\"]])\n",
    "print(\n",
    "    \"variablen 'geo' efter transformation:\\n\",\n",
    "    geo_transformed,\n",
    "    \"\\n#missings:\",\n",
    "    geo_transformed.isna().sum().sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pr. `sklearn.pipeline` konvention skal feature-specifikke transformationer defineres i en såkaldt [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). \n",
    "\n",
    "Med en `ColumnTransformer` har brugeren mulighed for at specificere, hvilke features, der konkret skal transformeres.\n",
    "\n",
    "Det er således i vores `ColumnTransformer`, vi specificerer, at de to ovenstående pipelines skal anvendes på hhv. alle numeriske og alle kategoriske features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"transformer_num\",\n",
    "            transformer_num,\n",
    "            make_column_selector(dtype_include=[\"number\"]),\n",
    "        ),\n",
    "        (\n",
    "            \"transformer_cat\",\n",
    "            transformer_cat,\n",
    "            make_column_selector(dtype_include=[\"category\"]),\n",
    "        ),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "# bemærk, vi bruger 'make_column_selector' dynamisk - altså når transformeren fittes - til at identificere features af en given type\n",
    "\n",
    "# sæt output-typen for transformeren til pandas.DataFrame for bedre at kunne inspicere output (ellers returnerer den et array, der er sværere at afkode)\n",
    "col_transformer.set_output(transform=\"pandas\")\n",
    "\n",
    "# vis resulterende column transformer\n",
    "col_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Komplet data-transformations-pipeline\n",
    "De ovenstående transformationer vil tilsammen kunne transformere vores træningsdata, så en logistisk regression kan fittes på de transformerede data.\n",
    "\n",
    "Vi sætter alle de ovenstående transformationer sammen til en samlet data-transformations-pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"drop_features_blacklist\", DropFeatures(blacklist)),\n",
    "        (\"drop_constant_features\", DropConstantFeatures(missing_values=\"ignore\")),\n",
    "        (\"col_transformer\", col_transformer),\n",
    "        (\n",
    "            \"drop_correlated_features\",\n",
    "            DropCorrelatedFeatures(threshold=0.95, missing_values=\"ignore\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# vis pipeline\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herefter kan vi let fitte den samlede pipeline på træningsdata, og derefter anvende den - også på nye datasæt og observationer.\n",
    "\n",
    "Når pipelinen fittes, læres de parametre, der skal bruges til de underliggende transformers f.eks. $\\mu$, $\\sigma$, medianer, mest frekvente kategorier osv. på træningsdatasættet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline på de første 1000 observationer i træningssættet\n",
    "pipe.fit(X_train.head(1000))\n",
    "\n",
    "# undersøg, hvilke features der fjernes af \"drop_correlated_features\"-transformeren\n",
    "corr_features = list(\n",
    "    set(pipe.named_steps[\"drop_correlated_features\"].feature_names_in_)\n",
    "    - set(pipe.named_steps[\"drop_correlated_features\"].get_feature_names_out())\n",
    ")\n",
    "print(\"Følgende features fjernes af 'drop_correlated_features'-transformeren:\", corr_features)\n",
    "\n",
    "# anvend pipeline på valideringssættet til illustration\n",
    "print(\"Valideringssættet efter transformation:\")\n",
    "pipe.transform(X_val.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-træning\n",
    "Med data-transformationerne på plads kan vi nu vende blikket mod vores predictor.\n",
    "\n",
    "Vi anvender `sklearn`'s implementation af [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Vi udvider derfor vores pipeline med denne predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiér LogisticRegression-predictor\n",
    "# vi skruer op for 'max_iter', da vi har relativt mange features\n",
    "# vi bruger en \"newton-cholesky\"-solver, der ifølge dokumentationen skulle være god til at håndtere datasæt med vores karakteristika\n",
    "predictor = LogisticRegression(max_iter=1000, solver=\"newton-cholesky\")\n",
    "\n",
    "# udvid pipeline med vores predictor\n",
    "pipe.steps.append([\"predictor\", predictor])\n",
    "\n",
    "# visualize pipeline\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan vores pipeline inkl. predictor fittes under ét på vores træningsdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dermed har vi succesfuldt \"trænet\" vores første model! &#127881;\n",
    "\n",
    "Denne model definerer vi som vores *baseline-model*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-evaluering\n",
    "\n",
    "Efter modellen er fittet, evalueres dens performance.\n",
    "\n",
    "Vi evaluerer både modellens prædiktive performance på træningssættet, som modellen er trænet på, og valideringssættet, som *modellen ikke har haft adgang til under træningen*. Performance på valideringssættet giver os en fornemmelse af, hvor godt modellen generaliserer til nye usete, data.\n",
    "\n",
    "Vi plotter &#128073; [ROC-kurverne](slides/05_roc_auc.ipynb) for modellen på trænings- og valideringssættet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beregn true positive rate og false positive rate for trænings- og valideringssæt\n",
    "# bemærk, når vi bruger pipe.predict, anvendes hele pipelinen (dvs. fittede transformers + fitted predictor) på input\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_train, [0 for _ in range(len(y_train))])\n",
    "train_fpr, train_tpr, _ = roc_curve(y_train, pipe.predict_proba(X_train)[:, 1])\n",
    "test_fpr, test_tpr, _ = roc_curve(y_val, pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "# plot ROC-kurver\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle=\"--\", label=\"Naïve\")\n",
    "plt.plot(train_fpr, train_tpr, label=\"Train\")\n",
    "plt.plot(test_fpr, test_tpr, label=\"Validation\")\n",
    "\n",
    "# formatér og display plot\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bemærker, at ROC-kurverne for træning- og valideringssættet forløber næsten identisk.\n",
    "\n",
    "Vi beregner for begge sæt [*ROC AUC*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score), som er den metrik, vi bestræber os på at optimere modellen i forhold til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beregn ROC AUC på både trænings- og valideringssæt\n",
    "auc_train_baseline = roc_auc_score(y_train, pipe.predict_proba(X_train)[:, 1])\n",
    "auc_val_baseline = roc_auc_score(y_val, pipe.predict_proba(X_val)[:, 1])\n",
    "print(\"ROC AUC train: \", auc_train_baseline, \"\\nROC AUC val: \", auc_val_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det bemærkes, at \n",
    "\n",
    "1. Modellen performer signifikant bedre end en naiv model (=tilfældigt gætteri) på både trænings- og valideringssæt\n",
    "2. Der er ikke nogen tegn på, at modellen *overfitter*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-diagnostik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vil ikke bruge tid på det her på workshoppen, men hvis man ønsker at komme et spadestik dybere ned i den fittede predictor, vil Data Scientists typisk inspicere model-egenskaber såsom \"Feature Importance\".\n",
    "\n",
    "For `LogisticRegression` er det nærmeste, man kommer det, en udskrift af de estimerede koefficienter.\n",
    "\n",
    "Da alle numeriske variable er standardiserede, kan den absolutte værdi af deres koefficienter med tolkes som udtryk for deres \"importance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"parameter\": pipe.named_steps[\n",
    "            \"drop_correlated_features\"\n",
    "        ].get_feature_names_out(),\n",
    "        \"coefficient\": pipe._final_estimator.coef_[0],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Machine Learning er man ikke som i traditionel statistik interesseret i inferens på feature-niveau, men langt mere i modellens prædiktive performance.\n",
    "\n",
    "Det er også oplagt eksempelvis at inspicere fordelingen af de prædikterede sandsynligheder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pipe.predict_proba(X_train)[:, 1])\n",
    "plt.xlim(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det ser tilforladeligt ud (?)\n",
    "\n",
    "Af andre nyttige plots og metrikker kan blandt andet nævnes [kalibreringsplots](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html), [precision/recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall), [F1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) og [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#confusion-matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "Da vi nu er i stand til at træne vores model, udestår sidste skridt - nemlig at &#128073; [*tune*](slides/07_tuning.ipynb) den.\n",
    "\n",
    "scikit-learns `LogisticRegression`-predictor implementerer som default [en tabsfunktion med regularisering](https://scikit-learn.org/stable/modules/linear_model.html#mathematical-details-3), der har regulariserings-parameteren $C$. Jo lavere/højere $C$, desto mere/mindre regularisering.\n",
    "\n",
    "Vi prøver derfor at tune modellens parameter $C$ med henblik på at forbedre modellens performance.\n",
    "\n",
    "Vi anvender et simpelt `GridSearch` til formålet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definér parameter-grid, der skal gennemsøges\n",
    "param_grid = {\n",
    "    \"predictor__C\": [1e-5, 1, 1e5],\n",
    "}\n",
    "\n",
    "# Forbered GridSearch\n",
    "# Bemærk, at vi bruger vores split_generator til at generere trænings- og valideringssæt\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=split_generator,\n",
    "    scoring=\"roc_auc\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "# Udfør grid search - bemærk, vi giver hele datasættet (2015-18) som input og overlader det til split-generatoren at splitte det i trænings- og valideringssæt\n",
    "grid.fit(df, y)\n",
    "\n",
    "print(\"Disse parametre giver den bedste performance: \", grid.best_params_)\n",
    "print(\"Med en ROC AUC på: \", grid.best_score_)\n",
    "auc_val_iter_2 = grid.best_score_\n",
    "\n",
    "# Udskriv resultater\n",
    "results = pd.DataFrame.from_records(grid.cv_results_[\"params\"])\n",
    "results[\"mean_valid_score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "results[\"mean_train_score\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "print(\"Resultater for grid search:\")\n",
    "results.sort_values(\"mean_valid_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det ses, at der ikke er noget at hente ved øget regularisering. Det giver mening, fordi der ikke er nogen tegn på, at modellen skulle være  &#128073; [overfittet](slides/06_overfitting.ipynb).\n",
    "\n",
    "En stor styrke ved, at vi har skrevet vores samlede model som en `sklearn.pipeline` er, at det gør det let at tune predictorens og data-transformationernes hyperparametre under ét.\n",
    "\n",
    "I eksemplet nedenfor tuner vi til illustration $C$ og strategien for vores imputation af numeriske variable under ét."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definér parameter-grid, der skal gennemsøges\n",
    "param_grid = {\n",
    "    \"predictor__C\": [1e-5, 1],\n",
    "    \"col_transformer__transformer_num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "}\n",
    "\n",
    "# Forbered GridSearch\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=split_generator,\n",
    "    scoring=\"roc_auc\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "# Udfør grid search\n",
    "grid.fit(df, y)\n",
    "\n",
    "print(\"Disse parametre giver den bedste performance: \", grid.best_params_)\n",
    "print(\"Med en ROC AUC på: \", grid.best_score_)\n",
    "auc_val_iter_3 = grid.best_score_\n",
    "\n",
    "# Udskriv resultater\n",
    "results = pd.DataFrame.from_records(grid.cv_results_[\"params\"])\n",
    "results[\"mean_valid_score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "results[\"mean_train_score\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "print(\"Resultater for grid search:\")\n",
    "results.sort_values(\"mean_valid_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi konstaterer, at vi med ovenstående eksperimenter ikke har været i stand til at forbedre vores model ift. *baseline*-modellen.\n",
    "\n",
    "Vi vedtager, at vi ikke vil investere mere energi i at tune modellen.\n",
    "\n",
    "Vores bedste resultat var en ROC AUC på følgende:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bedste ROC AUC: \", max(auc_val_baseline, auc_val_iter_2, auc_val_iter_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NB.** Bemærkninger om `sklearn.pipeline`\n",
    "\n",
    "Som sagt er der mange gode grunde til, hvorfor man bør skrive sin modelkode, som vi har gjort - altså med en `sklearn.pipeline`.\n",
    "\n",
    "Efter at have afprøvet teknikken i eksemplet ovenfor, kan man forhåbentligvis give mening til argumenterne, der er sammenfattet i &#128073; [disse slides](slides/10_pipelines.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
