{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ensemble-algoritme\n",
    "\n",
    "*Gradient Boosting Trees* (=*GBT*) er *ensemble*-algoritme, der bygger *mange* beslutningstræer, som kombineres til én samlet model. \n",
    "\n",
    "Prædiktionerne for den samlede model fås ved at aggregere prædiktionerne for de enkelte beslutningstræer.\n",
    "\n",
    "Tanken bag dette er at danne en *strong predictor* ud fra mange *weak predictors*.\n",
    "\n",
    "Nedenfor ses et eksempel på et enkelt beslutningstræ.\n",
    "\n",
    "<img src=\"https://bookdown.org/tpinto_home/Beyond-Additivity/tree.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sekventielle beslutningstræer\n",
    "\n",
    "*GBT* bygger beslutningstræerne *sekventielt*. \n",
    "\n",
    "Prædiktionerne for den samlede model aggregeres for hver iteration med prædiktionerne for det nye beslutningstræ.\n",
    "\n",
    "Hvert træ er bygget til at korrigere residualerne for den foregående model.\n",
    "\n",
    "![Sekventielle træer](https://www.researchgate.net/publication/335483097/figure/fig3/AS:934217085100032@1599746118459/A-general-architecture-of-XGBoost.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 'XGBoost'\n",
    "\n",
    "[*XGBoost*](https://xgboost.readthedocs.io/en/stable/) (eXtreme Gradient Boosting) er en implementation af Gradient Boosted Trees.\n",
    "\n",
    "XGBoost-algoritmen er virkelig populær og har været med til at vinde mange *kaggle*-konkurrencer (50% af alle inden for prædiktiv ML?).\n",
    "\n",
    "Det skriver andre om XGBoost:\n",
    "\n",
    "> It’s precise, it adapts well to all types of data and problems, it has excellent documentation, and overall it’s very easy to use. \n",
    ">\n",
    "> At the moment it’s the *de facto standard* algorithm for getting accurate results from predictive modeling with machine learning. It’s the fastest gradient-boosting library for R, Python, and C++ with very high accuracy.\"\n",
    "\n",
    "Kilde: [neptune.ai](https://neptune.ai/blog/xgboost-everything-you-need-to-know)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Virkemåde for 'XGBoost'\n",
    "\n",
    "- XGBoost bygger beslutningstræer sekventielt\n",
    "- Hvert nyt træ søger at korrigere fejlene for den foregående model, hvorved tabs-funktionen minimeres\n",
    "- Opgørelsen af tabsfunktionen i iteration $t$ udnytter information om gradienten til tabsfunktionen i iteration $t-1$\n",
    "- XGBoost implementerer desuden *regularisering* (og mange håndtag til det)\n",
    "- Prædiktionerne for den endelige/samlede model fås ved at aggregere prædiktionerne fra alle de underliggende træer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Læs mere om 'XGBoost'\n",
    "\n",
    "- [Det oprindelige paper bag 'XGBoost'](https://arxiv.org/pdf/1603.02754v3.pdf?)\n",
    "- ['What does XGBoost learn?'](https://speakerd.s3.amazonaws.com/presentations/5c6dab45648344208185d2b1ab4fdc95/XGBoost-Newest.pdf#page=9) - slides fra skaberen af 'XGBoost' om den underliggende matematik (se slides 9-26)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
