{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definition\n",
    "\n",
    "*Overfitting* er, når en ML-model lærer træningsdata for godt at kende og fanger støj og tilfældige fluktuationer i data frem for de underliggende/strukturelle mønstre.\n",
    "\n",
    "![Overfitting](img/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Årsager til overfitting\n",
    "\n",
    "- **høj modelkompleksitet**: komplekse modeller med et stort antal parametre er tilbøjelige til at overfitte, fordi de kan fitte data mere fleksibelt end mindre komplekse modeller.\n",
    "- **utilstrækkelig data**: jo mindre data man har at arbejde med, desto større risikoen for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implikationer af overfitting\n",
    "\n",
    "- **Dårlig evne til at generalisere**: Overfittede modeller performer godt på træningsdata, men generaliserer dårligt til nye, usete data, hvilket medfører dårlig performance på test- og validerings-data. \n",
    "- **Ustabile modeller**: Overfittede modeller har høj varians, hvilket vil sige at de er sensitive ift. små fluktuationer i træningsdata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Undgå overfitting\n",
    "Hvis modellen viser tegn på overfitting, kan man overveje følgende: \n",
    "\n",
    "- **Regularisering**: Anvend [regularisering](https://www.dataquest.io/blog/regularization-in-machine-learning/) til at straffe høje parameter-værdier \n",
    "- **Feature-selektion**: Vælg relevante features og drop irrelevante og redundante features for at simplificere modellen og reducere variansen på model-fittet\n",
    "- **Model-kompleksitet**: Vælg en mere simpel model eller arkitektur\n",
    "- **Anskaf flere data**: Det *dyre* alternativ, der ikke altid er en mulighed.\n",
    "\n",
    "Se også [denne gode ressource](https://mlu-explain.github.io/bias-variance/) om det såkaldte *Bias Variance Tradeoff*, der er helt centralt for overfitting-problematikken."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
